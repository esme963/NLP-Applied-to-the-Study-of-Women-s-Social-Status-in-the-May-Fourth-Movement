# -*- coding: utf-8 -*-
"""LDA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TszeSJw8deI-1bUzYRM1sQCjlaDzNo6H
"""

import pandas as pd
import jieba.posseg as pseg
from gensim import corpora, models
import re

# Stop words list，this is the final stop words with Dynamic Stopword Updating
stop_words = ["空气","余","先生","定价","刘猛","污点","大士","温度","利亚","小儿","水蒸气","种子","妇人",
        "婴儿","儿童","夫人","贵族","人人","能力","社会","妇女杂志","行川","白山","白心山",'陈穆堂',
        '山日巾','篇数',"刘嫂","欧文","小姐","国家","江苏","男子","义务","刘桂","女士","刘柱","向氏",
        "师爷","周氏","妇女","上海","国家","世界","有所","同胞","时期","动物","结果","现象","时时",
        "材料","物质","荣庆","国民","世人","父母","程度","陈老伦","家族","方法","小生","方面","偶人",
        "兄弟","原因","小时","窗户","老总","原名","黄督","玩人","右手","作何","斜线","女子","女郎",
        "右分","人生","状子","形势","长江","太君","植物","美国","谢赫","人口","时候","时间","情形","问题",
        "中国","事情","地方","东西","女性","玛丽","明白","地方","大家","密斯","维太命","女人","日本",
        "男人","时代","法国","人类","精神","澳门","目的","态度","印度","斯达埃","有点","朋友","人们",
        "产生","玛利","尼亚","合金","条例","经验","城市","明珠","英法","德奥","宪法","德国","肌肉",
        "慕凡","欧战","战区","景蕙","人家","法律","德军","凡尔登","姑娘","将军","罗马尼亚","议员","沈彤",
        "土耳其","杂芯","大事记","大兵","埃及","英国","波斯","污秽","杂品","习惯","基础","筋肉","整理",
        "全国","道德","北京","人民","中央","威色斯","神通","玉京","道理","中华民国","大总统","政府",
        "国会","会议","国务","战争","列席","命令","众议院","黄花","古人","祖先","弗兰克","日光","帝制",
        "人为","袁氏","校利","法儿","古话","用心","束西","洛克","红绿","神经","军械","炭酸","谓之",
        "蔡公","松雪","总统","势力","头骨","禁食","奴仆","大尉","盎斯","染法","爱克斯","娜亚","爱尔兰",
        "重量","血亏","体重","黄连","黄豆","成分","饮水","主义","地位","身体","热水","颜色","主人",
        "奴侯","文明","利益","成人","兄童","燕子","用情","男女","甲乙","先决问题","长安","标本","新鲜",
        "实数","红色","意志","手指","罪过","专门","染法","思想","娜亚","志琴","性质","中流","上帝","纽约",
        "前人","工蜂","伦敦","爱国","观者","赖尔夫","素秋","海伦","民族","风俗","清水","马格兰","神仙","夜服",
        "计画","沸水","脂肪","亨利","铜元","爱伦","科贝","南珊","阿凤","强盗","猛虎","感觉","生物",
        "阻力","汤姆","凶手","乡下人","美西","屋漏","看护人","空地","冷水","花边","金钱","余兴","军人",
        "西亚","哥哥","小娘子","设法","变种","利用","程生","老人","阻力","大娘","大人","身长","乡下人",
        "四娘","小玉","驴子","贵人","蚊虫","鼠疫","原料","知府","女生","光线","转体","部位","阿魏","曹达",
        "疫虫","官吏","蚊类","年龄","银行","智识","查礼斯","玉芬","居室","汝子","房屋","众人","全身","何谓",
        "苍蝇","奴家","部分","损失","慧瑛","秋鸿","罐头","上体","约翰","诸君","英兰","莫兰","小狐","玳姑",
        "老者","老太太","小丫头","丝线","发器","耳朵","沙漠","电统","列位","金属","清漪","阴电","村落","尾巴",
        "金器","水面","血液","轮廓","热度","欧洲","流水","消失","异状","田螺","二人","罪恶","鬼物","信息","船舰",
        "如斯","蜃气","物体","行人","证实","空际","令人","纳姿","动机","空空","深者","尤者","眼色","马利","责任",
        "问道","价贵","金子","金字","秋声","意思","品性","大地","生徒","仁慈","陆地","晚饭","令人","白色","青色",
        "甘蓝","中者","紫色","女维","热汤","海水","美丽","注人","视觉","时则","笔记","姿态","中约","灌人","河面",
        "大湖","事实","不平","宣言","中断","任凭","平原","农夫","神感","狐狸","尼罗河","老狐","规炬","方四","出品",
        "地面","英星","彼得","样子","用力","胶质","光彩","有色","软木","法子","气质","木球","阿哥","风声","绿色",
        "变色","狸奴","猎人","爱脱尔","缘故","香溪","海面","尖头","曲线","若莲","秋莲","动作","小虫","机关","前途",
        "大气","祝之","嫦女","杂姐","声响","报告","女字","浪费","偶丝帚","一碗水","长方","原理","原状","小岛","树胶",
        "杂时","夫人道","声音","碧莲","嫂子","弹词","嫂嫂","伯父","月光","少妇","珊珠","猎职","工州","山江","字列者",
        "囚汀","也瓜西","九洵","天真","记人","信面","警油","常事","盛行于","若夫","名目","品名","有益","欧美","长大",
        "火星","地球","安娜","娼妓","缝纫","经济","刘赛","沟渠","理想","功效","家蝇","本能","常识","乡村","利息","价值",
        "力量","形状","沟渠","代表","要素","薛氏","交际","中心","俱乐部","国旗","意见","答案","缺点","波尔特","用途","阶级",
        "范围","性情","宗教","佃人","托罗","昆虫","历史","本能","面针","杂访","形式","主张","丈夫","娼妓","米兰",
        "制度","色泽","盐基性","资格","权利","权利","论者","办法","契约","美的","意义","婢女","易卜生","本能",
        "托罗","中性","通论","社交","太太","两性","男性","亚尔","恩物","军队","观念","血轮","故事","玩物","王先生",
        "吕思","眼光","婢女","装饰","太阳","养气","公娼","一夫","标准","轻气","私娼","外国","心理","罗马","幼虫",
        "尔西","世纪","化验","关保","机会","界限","白话","时刻","全体","社论","理由","衙生","克拉","直接染料",
        "醋酸","丹宁","罗生","阿纳","绮罗","马罗凡","马克思","所欲","动力","种族","权力","灵魂","爱儿","猴子","图画",
        "女家","石生","体力","男家","海纳","检温","小猫","体温计","横线","行度","直线","房子","间题","体温","新娘",
        "功用","眼泪","奴隶","壮会","俄国","兴味","叔父","安静","状态","眼睛","民众","财产","养素","回家","不法","容器",
        "国王","含水","物性","植物性","悲剧","岱母","差异","仙人","海绒","体力","蟠女","条件","佛尔","大姨","刑罚","光明",
        "政党","石子","热症","部员","人间","死神","鱼类","鸟类","俄皇","火山","石守人","装置","员外","将球","白果","线下",
        "水分","太子","角环","环尔","事物","环度","芳姑","王女","野人","日数","国语","砍柴","野花","效果","大都","眼珠",
        "婶女","分子","小猫","老猫","表情","牛棚","神情","洛斯","分业","高尚","共产","亲戚","茉儿","马郎","德利","拜客",
        "错误","老实","质料","画片","叶片","角力","新郎","动物性","方向","须知","根源","传授","法人","花盆","炭素","食料",
        "人数","人格","棺材","油光","盒盖","环二","美洲","海草","弱点","温计","瓦尼亚","妮娜","食堂","巴恩","警告","伦凯",
        "心神","继母","巴利","光荣","活力","女王","老头子","力气","大嫂","党鱼","不料","卡菲尔","货币","俄罗斯","绿故",
        "箱子","名字","瑞典","屋子","赫夫","李宁","田野","天性","图形","笑颜","同志","言语","兵士","日子","兄子","天才",
        "一儡","法兰西","新闻","青草","总长","利己","常温","成亲","触觉","西伯利亚","薄膜","剧戟","八字","中段","不料",
        "实际","开花","摄氏","唐儿","百度","队员","芽胞","小人","消长","金银","敌队","起信论","大乘","容貌","同情","品格",
        "恶魔","劣点","商品化","东酉","喷口","关孙","仪式","始姻","地板","牛腿","新马尔","印虫","鲸鱼","卵子","窦器","法术",
        "君主","螟蛉","基督教","兹通","水汽","全气","克莱姆","手腕","开口","花儿","枝叶","岱父","臣民","大话","克斯","听力",
        "双方","救济","原子","参观","农村","老先生","流弊","制限","广告","原形质","沛尔","嫌女","普通","手段","异性",
        "母体","饥饿","大家族","同性","政治家","负气","外力","联邦","双方","待遇","老妇人","叶绿粒","原丝体","民国","种类",
        "少年时期","哈定","角度","格尔利","字宙","细胞","救济","参观","韶州","装饰品","农人","极端","物质文明","广州","男生",
        "人伦","证明","规定","天体","女权","商业","德国人","铁铁","道种","骨相","铁铁耳","钮扣","器具","司芬","物实","普通",
        "绮仲","因子","化合物","命运","性交","要旨","船客","甲板","故乡","性命","妖治","大伟","公门","利润","资本","罗府",
        "狂人","名言","环境","智能","不间","手笔","厨子","卡伊","参政","时用","证婚人","军乐","任务","战们","表面",
        "欧洲各国","保尔","科举","专家","西洋","平民","伦理","私生子","私生","数目","华希曲","金发","分会","白首","团员",
        "席间","倾袖","消息","高下","干事","禁令","微求","聚餐","门第","教会","遗毒","罐女","山口","朋子","史观","女儿",
        "密司","遭际","女孩子","拉丁文","宋九","流弊","血统","篇幅","目标","实任","肉眼","怪物","老处女","祖宗","体弹",
        "机运","文举","西式","征文","应征者","旧社会","口口","沛尔根","议论","信仰","天空","官能","树林","特伦","中世纪",
        "器械","无情","行星","水液","字条","著作","达尔文","桌椅","埃利","微粒","洗衣","正义","年老","双女","军备","脾步",
        "事面","别字","记契","孟子","农村妇女","母观","节省","面容","原故","肉体","交易","危害","心灵","戚谢","砖石","半常园",
        "亚贝","新郎新娘","牝马","小驹","相适应","表哥","表妹","铁耳","原则","正义","举校","姨母","心爱","新式","伯母","亲友",
        "死亡率","因光","重儿","特性","危害","交易","汇票","一务","水续","六国","分科","要质","浪子","科会","舅子","文夫",
        "亲子","本特","学说","理性","原质","维格","原故","肉体","我观","华伦夫人","行使","杀婴","水远","一事","境遇","智慧",
        "一偶","民法","白宫","做人","马尔撤","刑法","修正","主文","功夫","容态","陋劣","题日","海军","德文","政法","儿子","安庆",
        "特权","政治","天津","黑拉林","梅雨","少女","主席","胞子","尔思培","入梅","格拉","色彩","朝鲜","美人","院长","系统",
        "光度","有权","许可","神话","讲故事","椅子","荒原","威觉","幻影","十九世纪","财富","梅雨期","圣庙","走路","局部","特种",
        "性别","父权","花色","好孩子","忠告","村庄","污迹","投稿","克利","内生","老头儿","火焰","仆人","灰色","体格","绅士","合胞",
        "场所","纪尔曼","嬷嬷","少女","低语","女同胞","评论","双手","女孩","链霉","杜后","同形","荒原","法廷","思培思","拉克斯",
        "奥格","意中人","脱特","芽胞子","梅南","智俗","习俗","淡色","走子","老管家","知体","东海","梅尔","阴谋","希伯来","小孩",
        "酒精","气压","寰子","质间","秩序","葬花","流泪","大祸","下层","同班","物事","白分","私人","心理作用","小暑","梅雨","嫌恶",
        "少女","芒种","座位","天津","入梅","中举","小孩子","链条","中华民族","眸子","物象","华丽","光泽","声香","欲庐","洪水",
        "泥塑","情贩","美人","火焰","正则","慧巧","神圣","物件","修道士","传统","步骤","缺德","社肖","状况","时宜","过度","二十世纪",
        "神父","水桶","王君","广义","密歇尔劳特什思","臂膀","肺腑","马鞭","颈项","前额","压制","理智","证据","梁先生","著例","畜生",
        "出发点","仆人","权衡","蜜蜂","宰福","亭子","膝盖","流氓","联络","意识","产下","空虚","院子","因篱","杜子","武士",
        "舆论","悲戚","陌生","枝条","日暑","舅父","母马","速度","感光","全色","以太","忠者","网膜","民事","古罗马","作工","智惯",
        "格林","阴影","禄故","思体","条纹","夏令","儿歌","民治","名称","杨妃","讲话","意恩","宏博","议会","教调","西班牙","事件","现仕",
        "容纳","性格","女知","系就","什历","方针","堂叔","秘密","黛芬","地理","洗礼","水沟","火烧","格林","和善","真理","生涯","男权","身材",
        "原义","人站","林格尔","柔声","塞尔","身子","器物","圣母","本馆","耶稣","残址","大门","白画","晋谒","食言","火灾","骤雨","战业",
        "卡脱","小时候","心事","弗星特","须林娜","雅典","大石","寓言","少爷","克来门","马升","卧房","来门","哲人","麦歇","王妈","巴夷苏",
        "妮我","旧式","马丹","杜合尔","雅格","友朋","自山","效力","前卫","土语","场合","后卫","腹部","团体","金生","妮是","妮你","妮克",
        "翰妮","丫克","杜右尔","克来","贝尔","区别","趋势","乳皮","来潮","本质","石炭酸","巡长","头脑","人杰","舞手","两性间","老爷","威情",
        "木棒","柴克","天鹅","爱尔古达","汉蒂额","哲人","州郡","人物","竞技","日记","大战","肉麻","件侣","海姆","指导","法则","旧式","男孩子",
        "土地","协力","实力","皮面","国际","风化","前者","大会","过程","公理","比例","对方","人杰","右门","委势","才质","金生","苏维埃",
        "理论","委势","声调","本质","南美","幻梦","米突","被窝","幻想","儿董","包皮","男女性","豆凡","偶像","羁绊","用水","颚骨","黄色",
        "场合","自山","四肢","圈体","狮子","训令","治国","马哈","顾西","本性","白叶村","油垢","仙女","合众国","教长","第三者","误会","能砂",
        "记忆","杜古尔","原谅","齐家","澈底","姿势","劲儿","元贞","状心","阿蒲华","照例","浪漫史","葡萄牙","有所区别","话筒","生长","南美各国",
        "意味","脑筋","中古","限界","刘于","呼声","资本家","冰桶","姨太太","和尚","崇拜","行李","原谅","杜古尔","刘贵","能砂","记忆",
        "林肯","凌权","行经","裁法","皇帝","男孩","老婆子","婆婆","裴迦","玛丽亚","老人家","延章","凌权","光景","瓦丽蕊","好事","妹妹",
        "弟弟","祖母","天师","幼小","夜莺","情愿","费标","那星","草场","作法","投水","新石器","公主","小媳妇","光宗","部落","舟子","爸爸",
        "亚美利加","克劳斯","念头","婶母","消极","专制","阿猫","大臣","根部","水门汀","爱神","女巫","杨瑞华","杨达甫","威尔","肥料","仲德",
        "专号","吉嫂","福儿","爱密丽","少奶奶","乔笠","焦娜","工尺","方才","稻子","心肝","爹爹","大伯","姑婆","树木","尺工","上尺","乙五",
        "巴黎","右任","车路","和平","人心","水门汀","少奶奶","伤心","模样","老虎","房屋里","伍先生","慈爱","平道","伍老村","方桌","船长",
        "仙子","昭君","磨子","玉玲","生人","背景","小姑","泥土","水手","兽类","阿信","速动","人体","爱力","黄鹤楼","亲心","萤虫","水池",
        "池水","自然界","喇叭","钢针","美观","石版","步道","账目","列宁","杭州","围墙","茶客","圣婴","省党部","情绪","机能","倪克","表姐",
        "化炭","新妇","陶密","梅芬","修正案","英慧","调子","气味","雀儿","养化炭","广西","杏云","全世界","木屑","地们","产儿","乔尼","案件",
        "支那","黑人","爷娘","合法","外国人","异国","满蒙","司都","拉斯","法令","合理化","新大陆","柳州","全部","乞巧","谷芝","颜面","父亲",
        "智力","东北","青春","印象","董话","现实","信任","美金","桌子","数字","福斯","心身","白人","张妈","法庭","慧珊","香港","封信","事变",
        "生气","勇气","胡先生","整数","老夫","原色","像片","梅黛玲","对象","赫钦思","家长","内心","家事","陆克","笑话","外界","陆克道","技能",
        "沙利文","红果","赫狄思","秦珠","贾诗","时节","景象","美德","身心","绮芬","商量","史密斯","干片","陆思孟","影纹","加厚","小哥","乳汁",
        "天气","办事","阿勤","芳子","处分","假漆","计划","母猫","姊姊","王家","温性","存款","香气","存款","秋萍","无人","克勒","素质","谬误",
        "使婢","星亚","桂花","魔鬼","主母","姑母","巴谷","媒人","苏州","虚饰","丫一","麦芽","吸收率","弗利","精白米","柯达","球根","染料","石灰质",
        "吉利","姊妹","富家","不学","贾礼","铜子","奶奶","人种","新装","祖国","几偶","阿媛","技术","效率","山羊","容仪","二姐","梅县","费用",
        "式样","人性","白鸟","特质","双儿","夕明","荷泽","优点","石灰质","水村","杏花","博克","不容","大陆","黄君","阿美","公分","局长",
        "局长","农家","小鬼","沈三","男工","白努司","薄技","长罗","阿美","博克","乳母","浅识","王四嫂","胡家","尔德","沈三嫂","夫妻","教员",
        "事项","华林","义母","夫妇","菊花","映寒","二嫂","气体","福州","光阴","沈家","饲料","华侨","老翁","通风","断肠","亚硫酸","本务",
        "春桃","胡本立","哥德","九江","原人","心肠","伯谋","校长","沈君","恶鬼","工具","村民","补票","氏族","伟人","球状","无力","青任","曹操",
        "口角","白罕","星雾","言论","雅各","立体派","太郎","造物","造物","梅子","乔吉维","西纳","阿克","安妮","亚历山大","摩维","芙娜","希腊",
        "静弟","莎泻","多夫","训政","地主","华希理","莫斯科","乔古维","特米脱","达西","巴巴拉","彼得堡","楼板","妻称","雕刻","鬼胎","建筑","寺院",
        "矿石","中性线","居利","品质","阿齐","代价","消化率","早产","澄子","乔吉","约尼","屈服于","年青","帝国","加沙","意大利","冰心","魔王",
        "桃花","双胎","途径","入口","地步","社会主义","太平军","一妇","次第","宪政","孩儿","东京","苏俄","法王","服役","抵抗力","独立"]

# Filter text by part of speech
def filter_text_by_pos(words):
    filtered_words = []
    for word, pos in words:
        if pos.startswith("n"):  # Filter nouns
            filtered_words.append(word)
    return filtered_words

def process_dataset(text):
    # Chinese word segmentation and part-of-speech tagging
    words_pos = pseg.cut(text)
    # Filter text by part of speech
    filtered_words = filter_text_by_pos(words_pos)
    filtered_words = [word for word in filtered_words if word not in stop_words and len(word) > 1]
    return filtered_words

# Read a text file with newline as the separator，assuming 1931
file_path = '/content/clean_segment_1931.txt'  # File path

# Read file content using built-in file operations
with open(file_path, 'r', encoding='utf-8') as file:
    segment_1931_clean = file.read().splitlines()  # Read line by line and remove newline characters

# Print the first five elements to check the results
print(segment_1931_clean[0])  # Print only the first few elements

# Process each small dataset
segment_1931_filter = [process_dataset(segment) for segment in segment_1931_clean]

# Output the results
print(segment_1931_filter[0])

# Create a dictionary and a corpus
dictionary = corpora.Dictionary(segment_1931_filter)
corpus = [dictionary.doc2bow(text) for text in segment_1931_filter]

# Train the LDA model
lda_model = models.LdaModel(corpus, num_topics=10, id2word=dictionary, passes=60)

# Print the word distribution for each topic
print(lda_model.print_topics(num_topics=10, num_words=15))

# Calculate perplexity
def perplexity(num_topics):
    ldamodel = models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=60)
    print(ldamodel.print_topics(num_topics=num_topics, num_words=15))
    print(ldamodel.log_perplexity(corpus))
    return ldamodel.log_perplexity(corpus)

# Calculate coherence
def coherence(num_topics):
    ldamodel = models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=30, random_state=1)
    print(ldamodel.print_topics(num_topics=num_topics, num_words=10))
    ldacm = models.CoherenceModel(model=ldamodel, texts=segment_1931_filter, dictionary=dictionary, coherence='c_v')
    print(ldacm.get_coherence())
    return ldacm.get_coherence()

import matplotlib.pyplot as plt
import matplotlib

x = range(1, 15)
z = [perplexity(i) for i in x]  # Perplexity
# y = [coherence(i) for i in x]  # Coherence
plt.plot(x, z)
plt.xlabel('Number of Topics')
plt.ylabel('Perplexity')
matplotlib.rcParams['axes.unicode_minus'] = False
plt.title('Topic vs. Perplexity')
plt.show()

import matplotlib.pyplot as plt
import matplotlib

x = range(1, 15)
# z = [perplexity(i) for i in x]  # Perplexity
y = [coherence(i) for i in x]  # Coherence
plt.plot(x, y)
plt.xlabel('Number of Topics')
plt.ylabel('Coherence')
matplotlib.rcParams['axes.unicode_minus'] = False
plt.title('Topic vs. Coherence')
plt.show()

from gensim.models import LdaModel
import pandas as pd
from gensim.corpora import Dictionary
from gensim import corpora, models
import csv

dictionary = corpora.Dictionary(segment_1931_filter)
corpus = [dictionary.doc2bow(text) for text in segment_1931_filter]

# Train the LDA model with a chosen number of topics, assumed to be 10 here
lda_model = models.LdaModel(corpus, num_topics=10, id2word=dictionary, passes=60)

topic_list = lda_model.print_topics()
print(topic_list)

for i in lda_model.get_document_topics(corpus)[:]:
    listj = []
    for j in i:
        listj.append(j[1])
    bz = listj.index(max(listj))
    print(i[bz][0])

!pip install pyLDAvis

import pyLDAvis.gensim
pyLDAvis.enable_notebook()
data = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary)

from google.colab import drive
import pyLDAvis

# Path to save the HTML file in Colab
output_html_path = '/content/topic_1931.html'

# Visualize and save the HTML file
pyLDAvis.save_html(data, output_html_path)

# Display a message indicating that the file has been saved successfully
print("Visualization results have been saved to: " + output_html_path)

# Print the list of topics
topic_list = lda_model.print_topics()
print(topic_list)

# Define topic classification rules, manually determined based on visualization results
Family_and_Marriage_topics = {1, 2, 3, 4, 5, 7, 8}
Education_and_Culture_topics = {1, 2, 3, 4, 5, 6, 9}
Daily_Life_and_Consumption_topics = {1, 2, 3, 4, 7, 9, 10}
Health_and_Medicine_topics = {2, 4, 8, 9}
Economy_and_Social_Status_topics = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10}

# Create a dictionary for classification results
classification = {
    'Family_and_Marriage': [],
    'Education_and_Culture': [],
    'Daily_Life_and_Consumption': [],
    'Health_and_Medicine': [],
    'Economy_and_Social_Status': []
}

# Iterate through each document, get its main topic and classify
for doc_id, doc_topics in enumerate(lda_model.get_document_topics(corpus)):
    topic_weights = [weight for _, weight in doc_topics]
    main_topic_index = topic_weights.index(max(topic_weights))
    main_topic = doc_topics[main_topic_index][0] + 1

    if main_topic in Family_and_Marriage_topics:
        classification['Family_and_Marriage'].append(doc_id)
    if main_topic in Education_and_Culture_topics:
        classification['Education_and_Culture'].append(doc_id)
    if main_topic in Daily_Life_and_Consumption_topics:
        classification['Daily_Life_and_Consumption'].append(doc_id)
    if main_topic in Health_and_Medicine_topics:
        classification['Health_and_Medicine'].append(doc_id)
    if main_topic in Economy_and_Social_Status_topics:
        classification['Economy_and_Social_Status'].append(doc_id)

# Print the classification results
for category, documents in classification.items():
    print(f"{category} documents: {documents}")

# Save the classification results to a CSV file
with open('document_classification_1931.csv', mode='w', newline='', encoding='utf-8') as file:
    writer = csv.writer(file)
    writer.writerow(['Category', 'Document ID'])

    for category, documents in classification.items():
        for doc_id in documents:
            writer.writerow([category, doc_id])

data_Family_and_Marriage= []
data_Family_and_Marriage_id= []
data_Education_and_Culture_topics= []
data_Education_and_Culture_topics_id= []
data_Daily_Life_and_Consumption= []
data_Daily_Life_and_Consumption_id= []
data_Health_and_Medicine= []
data_Health_and_Medicine_id= []
data_Economy_and_Social_Status= []
data_Economy_and_Social_Status_id= []

# Read the file
df = pd.read_csv('/content/document_classification_1931.csv')

# Iterate through each row and add file_id to the corresponding theme list
for _, row in df.iterrows():
    theme = row['Category']
    file_id = row['Document ID']
    if theme == 'Family_and_Marriage':
        data_Family_and_Marriage.append(segment_1931_clean[file_id])
        data_Family_and_Marriage_id.append(file_id)
    elif theme == 'Education_and_Culture':
        data_Education_and_Culture.append(segment_1931_clean[file_id])
        data_Education_and_Culture_id.append(file_id)
    elif theme == 'Daily_Life_and_Consumption':
        data_Daily_Life_and_Consumption.append(segment_1931_clean[file_id])
        data_Daily_Life_and_Consumption_id.append(file_id)
    elif theme == 'Health_and_Medicine':
        data_Health_and_Medicine.append(segment_1931_clean[file_id])
        data_Health_and_Medicine_id.append(file_id)
    elif theme == 'Economy_and_Social_Status':
        data_Economy_and_Social_Status.append(segment_1931_clean[file_id])
        data_Economy_and_Social_Status_id.append(file_id)

# Print the classification results
print("Family_and_Marriage_len:", len(data_Family_and_Marriage))
print("Education_and_Culture_len:", len(data_Education_and_Culture))
print("Daily_Life_and_Consumption_len:", len(data_Daily_Life_and_Consumption))
print("Health_and_Medicine_len:", len(data_Health_and_Medicine))
print("Economy_and_Social_Status_len:", len(data_Economy_and_Social_Status))

# Calculate lengths
family_and_marriage_len = len(data_Family_and_Marriage)
education_and_culture_len = len(data_Education_and_Culture)
daily_life_and_consumption_len = len(data_Daily_Life_and_Consumption)
health_and_medicine_len = len(data_Health_and_Medicine)
economy_and_social_status_len = len(data_Economy_and_Social_Status)

# Create data dictionary
data = {
    "Category": [
        "Family_and_Marriage_len",
        "Education_and_Culture_len",
        "Daily_Life_and_Consumption_len",
        "Health_and_Medicine_len",
        "Economy_and_Social_Status_len"
    ],
    "1931": [
        family_and_marriage_len,
        education_and_culture_len,
        daily_life_and_consumption_len,
        health_and_medicine_len,
        economy_and_social_status_len
    ]
}

# Create DataFrame
df = pd.DataFrame(data)

# Save as CSV file
df.to_csv("/content/keywords_by_year.csv", index=False)

print("CSV file 'keywords_by_year.csv' has been created.")

# Perform topic time series analysis
def topic_time(data):
    count = 0
    data_topic_time = []
    for i in range(1, len(segment_1931_clean) + 1):
        if i % 150 == 0:
            data_topic_time.append(count)
            count = 0
        elif i in data:
            count += 1
    return data_topic_time

data_Family_and_Marriage_time= topic_time(data_Family_and_Marriage_id)
data_Education_and_Culture_topics_time= topic_time(data_Education_and_Culture_topics_id)
data_Daily_Life_and_Consumption_time= topic_time(data_Daily_Life_and_Consumption_id)
data_Health_and_Medicine_time= topic_time(data_Health_and_Medicine_id)
data_Economy_and_Social_Status_time= topic_time(data_Economy_and_Social_Status_id)

import pandas as pd

# Data definition, the data comes from the 17 years of results; extracting this data to reduce runtime for processing 17 files
data = {
    'year': [1915, 1916, 1917, 1918, 1919, 1920, 1921, 1922, 1923, 1924, 1925, 1926, 1927, 1928, 1929, 1930, 1931],
    'Family_and_Marriage': [0.246589717, 0.253692234, 0.251744637, 0.217736908, 0.175929026, 0.239485403, 0.262264151, 0.240032547, 0.235924933, 0.236667628, 0.258161648, 0.268025078, 0.256219904, 0.202204929, 0.262239457, 0.224456841, 0.199820184],
    'Education_and_Culture': [0.216509269, 0.286088614, 0.251744637, 0.21867207, 0.311181788, 0.215116279, 0.146540881, 0.215622457, 0.179624665, 0.210147016, 0.258161648, 0.225008708, 0.198836276, 0.2461738, 0.199951527, 0.204051674, 0.200944032],
    'Daily_Life_and_Consumption': [0.244840853, 0.206526918, 0.251744637, 0.21867207, 0.204218279, 0.215116279, 0.226415094, 0.18551668, 0.112600536, 0.168924762, 0.125673534, 0.193312435, 0.210272873, 0.173670558, 0.185409598, 0.201262478, 0.195774331],
    'Health_and_Medicine': [0.139209514, 0.135540734, 0.145257172, 0.228179551, 0.106126548, 0.090796635, 0.129559748, 0.146460537, 0.235924933, 0.147592966, 0.127099842, 0.07262278, 0.094502408, 0.131776913, 0.098885119, 0.102613036, 0.11553158],
    'Economy_and_Social_Status': [0.152850647, 0.118151501, 0.099508917, 0.116739401, 0.202544359, 0.239485403, 0.235220126, 0.212367779, 0.235924933, 0.236667628, 0.230903328, 0.241031, 0.240168539, 0.2461738, 0.2535143, 0.267615972, 0.287929872]
}

# Create DataFrame
df = pd.DataFrame(data)

# Save to CSV file
csv_path = '/content/topic.csv'
df.to_csv(csv_path, index=False)

# Print DataFrame
print(df)

import matplotlib.pyplot as plt

# Save pie charts for each year
for year in df['year']:
    row = df[df['year'] == year]
    labels = ['Family_and_Marriage', 'Education_and_Culture', 'Daily_Life_and_Consumption', 'Health_and_Medicine', 'Economy_and_Social_Status']
    sizes = row[labels].values.flatten()

    plt.figure(figsize=(8, 8))
    plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=140)
    plt.title(f'Year {year}')
    plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.

    # Save pie chart
    plt.savefig(f'pie_chart_{year}.png')
    plt.close()

print("Pie charts have been saved.")

# Create and save line charts for each category
categories = ['Family_and_Marriage', 'Education_and_Culture', 'Daily_Life_and_Consumption', 'Health_and_Medicine', 'Economy_and_Social_Status']
for category in categories:
    plt.figure(figsize=(15, 5))  # Increase the width of the figure
    plt.plot(df['year'], df[category], marker='o', label=category)
    plt.title(f'{category} Over Years')
    plt.xlabel('Year')
    plt.ylabel('Proportion')
    plt.grid(True)
    plt.xticks(df['year'], rotation=45, ha='right')  # Rotate x-axis labels
    plt.legend()
    plt.tight_layout()
    # Save the image
    plt.savefig(f'{category}_line_chart.png')
    plt.close()

print("Line charts have been saved.")